{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DrlWzkzVscKI"
      },
      "outputs": [],
      "source": [
        "# ! pip install -U accelerate\n",
        "# ! pip install -U transformers\n",
        "\n",
        "# import os\n",
        "# os._exit(00)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsLIQEGFBsHe",
        "outputId": "d826c058-1464-421a-8f63-c7a00e42ffcb"
      },
      "outputs": [],
      "source": [
        "# # Connect to Google Drive and upload a folder\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wP6l09IkDF6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/anastasiia.demidova/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# import numpy as np\n",
        "import torch\n",
        "import re # Regular expression\n",
        "import os\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from typing import List, Dict, Union\n",
        "from transformers import pipeline\n",
        "from transformers import Trainer, TrainingArguments, AutoTokenizer\n",
        "# from transformers import DataCollatorForTokenClassification\n",
        "# from transformers import AutoModelForTokenClassification\n",
        "\n",
        "# from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "# import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiZ2GWjJF6-q"
      },
      "source": [
        "## Downloading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9FgBOnngEgB-"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/s-nlp/semantic-role-labelling.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "T_OsWLxbDOPw"
      },
      "outputs": [],
      "source": [
        "path = '/home/anastasiia.demidova/srl/srl_transformers/dataset/train.tsv'\n",
        "path_dev = '/home/anastasiia.demidova/srl/srl_transformers/dataset/dev.tsv'\n",
        "# path = '/content/drive/MyDrive/Colab Notebooks/NLP_project/train.tsv'\n",
        "# path_dev = '/content/drive/MyDrive/Colab Notebooks/NLP_project/dev.tsv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xx3Ki_gwEd4R"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(path, sep='\\t', header= None, names=['data', 'label'],\n",
        "                 quoting=3, skip_blank_lines=False).fillna('_nan')\n",
        "\n",
        "df_dev = pd.read_csv(path_dev, sep='\\t', header= None, names=['data', 'label'],\n",
        "                 quoting=3, skip_blank_lines=False).fillna('_nan')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "vD8Hfq9JEd0u",
        "outputId": "c81d4984-8dff-40a2-c0b9-6fb8ab99844a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>also</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>recently</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>discovered</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>advil</td>\n",
              "      <td>B-Object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>liquigels</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>work</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>much</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>better</td>\n",
              "      <td>B-Predicate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>faster</td>\n",
              "      <td>B-Predicate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>for</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>a</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>headache</td>\n",
              "      <td>B-Aspect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>than</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>regular</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ibuprofen</td>\n",
              "      <td>B-Object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>_nan</td>\n",
              "      <td>_nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>i</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          data        label\n",
              "0         also            O\n",
              "1            ,            O\n",
              "2            i            O\n",
              "3         have            O\n",
              "4     recently            O\n",
              "5   discovered            O\n",
              "6        advil     B-Object\n",
              "7    liquigels            O\n",
              "8         work            O\n",
              "9         much            O\n",
              "10      better  B-Predicate\n",
              "11         and            O\n",
              "12      faster  B-Predicate\n",
              "13         for            O\n",
              "14           a            O\n",
              "15    headache     B-Aspect\n",
              "16        than            O\n",
              "17     regular            O\n",
              "18   ibuprofen     B-Object\n",
              "19           .            O\n",
              "20        _nan         _nan\n",
              "21           i            O"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(22)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "w9POFiZ1fmyN",
        "outputId": "7a86d53a-ab35-4a2f-f183-7b1b9b268dcb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>meanwhile</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>though</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>windows</td>\n",
              "      <td>B-Object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>I-Object</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        data     label\n",
              "0  meanwhile         O\n",
              "1          ,         O\n",
              "2     though         O\n",
              "3    windows  B-Object\n",
              "4          8  I-Object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_dev.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stOeO7E1Edyp",
        "outputId": "77c41c50-49ed-43ee-95f2-04e728199861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((63408, 2), (8646, 2))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape, df_dev.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YdDAVXUlEdwO",
        "outputId": "796dabed-d63c-4261-a68b-23bfbff262ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\"'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.data[592]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3NJ9KZWF-cs"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WD8RVXXtGMHp"
      },
      "source": [
        "    - Separating data into sentences with empty lines (NaN).\n",
        "    - Clean punctuation into single dot.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NftPLmrSXREJ"
      },
      "source": [
        "#### T5"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ReD4PeWB6zpL"
      },
      "source": [
        "[two, four | money]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "[ search results | aspect ] [ bing , google | object ] [ not , superior | predicate ]\n",
        "'''\n",
        "# [ search results | aspect ] [ bing | object ] [ not | predicate ] [ superior | predicate ] [ google | object ] not quite well\n",
        "\n",
        "BIO = ['aspect', 'object', 'predicate']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[two, four | OBJ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# '''\n",
        "# ### Instruction: Find all aspects , objects and predicates .\n",
        "\n",
        "# ### Input: in the content of search results , bing is not consistently superior to google .\n",
        "\n",
        "# ### Response: [ search results | ASP ] [ bing , google | OBJ ] [ not , superior | PRE ]\n",
        "# '''\n",
        "\n",
        "# BIO = ['ASP', 'OBJ', 'PRE']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[two, four | 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# '''\n",
        "# ### Instruction: Find all aspects , objects and predicates .\n",
        "\n",
        "# ### Input: in the content of search results , bing is not consistently superior to google .\n",
        "\n",
        "# ### Response: [ search results | 0 ] [ bing , google | 1 ] [ not , superior | 2 ]\n",
        "# '''\n",
        "\n",
        "# BIO = ['0', '1', '2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# '''\n",
        "# ### Instruction: Find all aspects , objects and predicates .\n",
        "\n",
        "# ### Input: _input_\n",
        "\n",
        "# ### Response:\n",
        "# '''\n",
        "\n",
        "# pattern = [\"###\", \"Instruction:\", \"Find\", \"all\", \"aspects\", \",\", \"objects\", \"and\", \"predicates\", \".\\n\\n###\", \"Input:\"]\n",
        "# end_pattern = [\"\\n\\n###\", \"Response:\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Sentence: in the content of search results , bing is not consistently superior to google . \n",
        "\n",
        "aspect , object and predicate :\n",
        "'''\n",
        "\n",
        "PATTERN = [\"Sentence:\"]\n",
        "END_PATTERN = [\"\\n\\naspect\", \",\", \"object\", \"and\", \"predicate\", \":\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separating data into sentences with empty lines (NaN)\n",
        "\n",
        "def separate_text(df):\n",
        "    a_pattern = ['|', BIO[0],']']\n",
        "    o_pattern = ['|', BIO[1],']']\n",
        "    p_pattern = ['|', BIO[2],']']\n",
        "    sep = ','\n",
        "\n",
        "    input = [] # for input\n",
        "    output = []\n",
        "    sentence = []\n",
        "    prev_tag = ''\n",
        "    temp_a = False\n",
        "    temp_o = False\n",
        "    temp_p = False\n",
        "    a = [] # aspects\n",
        "    o = [] # objects\n",
        "    p = [] # predicates\n",
        "\n",
        "    for word, tag in df.values:\n",
        "        if word == '_nan':\n",
        "            input.append(PATTERN + sentence + END_PATTERN)\n",
        "            if len(a) != 0 and a[-1] == sep: del a[-1]\n",
        "            if len(o) != 0 and o[-1] == sep: del o[-1]\n",
        "            if len(p) != 0 and p[-1] == sep: del p[-1]\n",
        "            output.append(['['] + a + a_pattern + ['['] + o + o_pattern + ['['] + p + p_pattern)\n",
        "            sentence = []\n",
        "            a = []\n",
        "            o = []\n",
        "            p = []\n",
        "            temp_a = False\n",
        "            temp_o = False\n",
        "            temp_p = False\n",
        "            prev_tag = ''\n",
        "        else:\n",
        "            tag = tag.lower()\n",
        "            word = re.sub(r\"[\\\"\\—\\#\\$\\%\\&\\'\\(\\)\\*\\+\\,\\–\\-\\/\\:\\;\\<\\=\\>\\?\\@\\[\\\\\\]\\^\\?\\!\\_\\`\\{\\|\\}\\~\\«\\»ѣ\\№]\", \",\", word)\n",
        "            word = re.sub(r\"[,]+\", \",\", word)\n",
        "            word = re.sub(r\"[.]+\", \".\", word)\n",
        "\n",
        "            # If prev tag was the last one in a tag set\n",
        "            if prev_tag.split('-')[-1] != tag.split('-')[-1] or 'B-' in tag:\n",
        "                if temp_a: #tag.split('-')[-1] == 'aspect':\n",
        "                        a.append(sep)\n",
        "                        temp_a = False\n",
        "                if temp_o: #tag.split('-')[-1] == 'object':\n",
        "                        o.append(sep)\n",
        "                        temp_o = False\n",
        "                if temp_p: #tag.split('-')[-1] == 'predicate':\n",
        "                        p.append(sep)\n",
        "                        temp_p = False\n",
        "\n",
        "            if 'O' not in tag:\n",
        "                if tag.split('-')[-1] == 'aspect':\n",
        "                        a.append(word)\n",
        "                        temp_a = True\n",
        "                if tag.split('-')[-1] == 'object':\n",
        "                        o.append(word)\n",
        "                        temp_o = True\n",
        "                if tag.split('-')[-1] == 'predicate':\n",
        "                        p.append(word)\n",
        "                        temp_p = True\n",
        "\n",
        "            prev_tag = tag\n",
        "            sentence.append(word)\n",
        "\n",
        "    return input, output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['Sentence:', 'also', ',', 'i', 'have', 'recently', 'discovered', 'advil', 'liquigels', 'work', 'much', 'better', 'and', 'faster', 'for', 'a', 'headache', 'than', 'regular', 'ibuprofen', '.', '\\n\\naspect', ',', 'object', 'and', 'predicate', ':']]\n",
            "[['[', 'headache', '|', 'aspect', ']', '[', 'advil', ',', 'ibuprofen', '|', 'object', ']', '[', 'better', ',', 'faster', '|', 'predicate', ']']]\n"
          ]
        }
      ],
      "source": [
        "input, output = separate_text(df.iloc[:22])\n",
        "\n",
        "print(input)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wE-5otEYuA5C"
      },
      "outputs": [],
      "source": [
        "# Appling cleaning to df\n",
        "input, output = separate_text(df)\n",
        "input_dev, output_dev = separate_text(df_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKzdWkfbuA5D",
        "outputId": "eaabfbf0-06ec-4207-fccb-2bcbf790b6b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: in the content of search results , bing is not consistently superior to google . \n",
            "\n",
            "aspect , object and predicate :\n",
            "[ search results | aspect ] [ bing , google | object ] [ not , superior | predicate ]\n"
          ]
        }
      ],
      "source": [
        "print(' '.join(input[-1]))\n",
        "print(' '.join(output[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auDVK0SJt1lo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGbFgE2LtQqC"
      },
      "source": [
        "## Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "p4Dmeaw9iXGY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/anastasiia.demidova/miniconda3/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "### T5 # 6ep_8b\n",
        "\n",
        "MODEL_NAME = 't5-large'\n",
        "IS_ENCODER_DECODER = True\n",
        "\n",
        "# tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ### FLAN-T5 # 4ep_8b\n",
        "\n",
        "# MODEL_NAME = 'flan-t5'\n",
        "# MODEL_HF_NAME = 'google/flan-t5-large'\n",
        "# IS_ENCODER_DECODER = True\n",
        "\n",
        "# # tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_HF_NAME)\n",
        "\n",
        "# model = T5ForConditionalGeneration.from_pretrained(MODEL_HF_NAME).to('cuda')\n",
        "\n",
        "# tokenizer.eos_token = '</s>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vSiOAP1ciXGb"
      },
      "outputs": [],
      "source": [
        "class PairsDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        assert idx <= len(self.x['input_ids']), (idx, len(self.x['input_ids']))\n",
        "        item = {key: val[idx] for key, val in self.x.items()}\n",
        "\n",
        "        item['labels'] = self.y['input_ids'][idx]\n",
        "        if IS_ENCODER_DECODER: item['decoder_attention_mask'] = self.y['attention_mask'][idx]\n",
        "\n",
        "        return item\n",
        "\n",
        "    @property\n",
        "    def n(self):\n",
        "        return len(self.x['input_ids'])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9TQML3Jpn80_"
      },
      "outputs": [],
      "source": [
        "class DataCollatorWithPadding:\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        batch = self.tokenizer.pad(\n",
        "            features,\n",
        "            padding=True\n",
        "        )\n",
        "\n",
        "        if IS_ENCODER_DECODER:\n",
        "            ybatch = self.tokenizer.pad(\n",
        "                {'input_ids': batch['labels'], 'attention_mask': batch['decoder_attention_mask']},\n",
        "                padding=True\n",
        "            )\n",
        "        else:\n",
        "            ybatch = self.tokenizer.pad(\n",
        "            {'input_ids': batch['labels']},\n",
        "            padding=True\n",
        "            )\n",
        "\n",
        "        batch['labels'] = ybatch['input_ids']\n",
        "\n",
        "        if IS_ENCODER_DECODER: batch['decoder_attention_mask'] = ybatch['attention_mask']\n",
        "\n",
        "\n",
        "        return {k: torch.tensor(v) for k, v in batch.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mehyGEOkkrO",
        "outputId": "88fbd224-3ef1-4bda-9351-608d3adce782"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "108"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max = 0\n",
        "for o in input:\n",
        "    if max < len(o):\n",
        "        max = len(o)\n",
        "max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "RKlZ3AwVjcFd"
      },
      "outputs": [],
      "source": [
        "### T5\n",
        "MAX_LENGTH = 128\n",
        "\n",
        "train_dataset = PairsDataset(tokenizer(input, padding='max_length', max_length=MAX_LENGTH, is_split_into_words=True),\n",
        "                             tokenizer(output, padding='max_length', max_length=MAX_LENGTH, is_split_into_words=True))\n",
        "dev_dataset = PairsDataset(tokenizer(input_dev, padding='max_length', max_length=MAX_LENGTH, is_split_into_words=True),\n",
        "                           tokenizer(output_dev, padding='max_length', max_length=MAX_LENGTH, is_split_into_words=True))\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "# data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhcgUXgCjcFd",
        "outputId": "054450b9-5ac7-491a-9313-d9761d2d3ad1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "128 128\n",
            "1 1 \t 784 \t 4892 \t ▁Sen \t ▁[\n",
            "1 1 \t 12085 \t 17 \t t \t ▁headache\n",
            "1 1 \t 1820 \t 1433 \t ence \t ▁|\n",
            "1 1 \t 2663 \t 10 \t : \t ▁aspect\n",
            "1 1 \t 3 \t 92 \t ▁also \t ▁\n",
            "1 1 \t 908 \t 3 \t ▁ \t ]\n",
            "1 1 \t 784 \t 6 \t , \t ▁[\n",
            "1 1 \t 3 \t 3 \t ▁ \t ▁\n",
            "1 1 \t 9 \t 23 \t i \t a\n",
            "1 1 \t 26 \t 43 \t ▁have \t d\n",
            "1 1 \t 6372 \t 1310 \t ▁recently \t vil\n",
            "1 1 \t 3 \t 3883 \t ▁discovered \t ▁\n",
            "1 1 \t 6 \t 3 \t ▁ \t ,\n",
            "1 1 \t 3 \t 9 \t a \t ▁\n",
            "1 1 \t 23 \t 26 \t d \t i\n",
            "1 1 \t 3007 \t 6372 \t vil \t bu\n",
            "1 1 \t 1409 \t 3 \t ▁ \t pro\n",
            "1 1 \t 89 \t 40 \t l \t f\n",
            "1 1 \t 35 \t 23 \t i \t en\n",
            "1 1 \t 1820 \t 1169 \t qui \t ▁|\n",
            "1 1 \t 3735 \t 1803 \t gel \t ▁object\n",
            "1 1 \t 3 \t 7 \t s \t ▁\n",
            "1 1 \t 908 \t 161 \t ▁work \t ]\n",
            "1 1 \t 784 \t 231 \t ▁much \t ▁[\n",
            "1 1 \t 394 \t 394 \t ▁better \t ▁better\n",
            "1 1 \t 3 \t 11 \t ▁and \t ▁\n",
            "1 1 \t 6 \t 3627 \t ▁faster \t ,\n",
            "1 1 \t 3627 \t 21 \t ▁for \t ▁faster\n",
            "1 1 \t 1820 \t 3 \t ▁ \t ▁|\n",
            "1 1 \t 554 \t 9 \t a \t ▁pre\n",
            "1 1 \t 4370 \t 12085 \t ▁headache \t dic\n",
            "1 1 \t 342 \t 145 \t ▁than \t ate\n",
            "1 1 \t 3 \t 1646 \t ▁regular \t ▁\n",
            "1 1 \t 908 \t 3 \t ▁ \t ]\n",
            "1 1 \t 1 \t 23 \t i \t </s>\n",
            "1 0 \t 0 \t 3007 \t bu \t <pad>\n",
            "1 0 \t 0 \t 1409 \t pro \t <pad>\n",
            "1 0 \t 0 \t 89 \t f \t <pad>\n",
            "1 0 \t 0 \t 35 \t en \t <pad>\n"
          ]
        }
      ],
      "source": [
        "temp_f = train_dataset[0]\n",
        "\n",
        "print(len(temp_f['attention_mask']), len(temp_f['decoder_attention_mask']))\n",
        "\n",
        "z=0\n",
        "for i, d, j, k, c, l in zip(temp_f['attention_mask'],\n",
        "                            temp_f['decoder_attention_mask'],\n",
        "                            temp_f['labels'],\n",
        "                            temp_f['input_ids'],\n",
        "                            tokenizer.convert_ids_to_tokens(temp_f['input_ids']),\n",
        "                            tokenizer.convert_ids_to_tokens(temp_f['labels'])):\n",
        "\n",
        "    z+=1\n",
        "    if z == 40:\n",
        "        break\n",
        "    print(i, d, '\\t', j, '\\t', k, '\\t', c, '\\t', l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_PROJECT\"] = \"<nlp-project>\" # name your W&B project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run = wandb.init(\n",
        "#     project=\"nlp-project\",\n",
        "#     notes=\"\", tags=[\"t5\", \"project\"], resume=True\n",
        "# )\n",
        "# os.environ[\"WANDB_RESUME\"] = \"allow\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "EkZD3mD7jcFe"
      },
      "outputs": [],
      "source": [
        "N_EPOCHS = 6\n",
        "BATCH_SIZE = 8\n",
        "run_name = f'{MODEL_NAME}_{N_EPOCHS}ep_{BATCH_SIZE}b'\n",
        "\n",
        "args = TrainingArguments(output_dir=\"logs/model\",\n",
        "                         num_train_epochs=N_EPOCHS,\n",
        "                         per_device_train_batch_size=BATCH_SIZE,\n",
        "                         per_device_eval_batch_size=BATCH_SIZE,\n",
        "                         save_steps=10000000,\n",
        "                         logging_steps=200,\n",
        "                         report_to=\"wandb\",  # enable logging to W&B\n",
        "                         run_name=run_name,  # name of the W&B run (optional)\n",
        "                         #  load_best_model_at_end = False,\n",
        "                         evaluation_strategy = 'epoch',\n",
        "                         #  optim='adamw_torch',\n",
        "                         #  weight_decay=0.01,\n",
        "                         )\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = dev_dataset,\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator = data_collator,\n",
        "    # compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "PhJFC0L4jcFe",
        "outputId": "a0c2cb39-fa10-4a67-f6b7-66c1b5bfacba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprofii\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/anastasiia.demidova/srl/srl_transformers/wandb/run-20231110_114035-boa9oyfd</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/profii/%3Cnlp-project%3E/runs/boa9oyfd' target=\"_blank\">t5-large_6ep_8b</a></strong> to <a href='https://wandb.ai/profii/%3Cnlp-project%3E' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/profii/%3Cnlp-project%3E' target=\"_blank\">https://wandb.ai/profii/%3Cnlp-project%3E</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/profii/%3Cnlp-project%3E/runs/boa9oyfd' target=\"_blank\">https://wandb.ai/profii/%3Cnlp-project%3E/runs/boa9oyfd</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1752 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            " 11%|█▏        | 200/1752 [02:18<18:09,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3591, 'learning_rate': 4.4292237442922375e-05, 'epoch': 0.68}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                  \n",
            " 17%|█▋        | 292/1752 [03:30<16:12,  1.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.053233131766319275, 'eval_runtime': 7.0586, 'eval_samples_per_second': 40.093, 'eval_steps_per_second': 5.1, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 400/1752 [04:47<15:47,  1.43it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0415, 'learning_rate': 3.8584474885844754e-05, 'epoch': 1.37}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                  \n",
            " 33%|███▎      | 584/1752 [07:03<12:54,  1.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.048347581177949905, 'eval_runtime': 6.998, 'eval_samples_per_second': 40.44, 'eval_steps_per_second': 5.144, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 600/1752 [07:14<13:31,  1.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0318, 'learning_rate': 3.287671232876712e-05, 'epoch': 2.05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 800/1752 [09:35<11:05,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0241, 'learning_rate': 2.71689497716895e-05, 'epoch': 2.74}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                  \n",
            " 50%|█████     | 876/1752 [10:35<09:48,  1.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.04894203320145607, 'eval_runtime': 6.9525, 'eval_samples_per_second': 40.705, 'eval_steps_per_second': 5.178, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 1000/1752 [12:02<08:42,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0205, 'learning_rate': 2.1461187214611872e-05, 'epoch': 3.42}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                   \n",
            " 67%|██████▋   | 1168/1752 [14:08<06:22,  1.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.05329310521483421, 'eval_runtime': 6.9791, 'eval_samples_per_second': 40.549, 'eval_steps_per_second': 5.158, 'epoch': 4.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 1200/1752 [14:30<06:28,  1.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0172, 'learning_rate': 1.5753424657534248e-05, 'epoch': 4.11}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 1400/1752 [16:51<04:07,  1.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0148, 'learning_rate': 1.004566210045662e-05, 'epoch': 4.79}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                   \n",
            " 83%|████████▎ | 1460/1752 [17:40<03:12,  1.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.05591963976621628, 'eval_runtime': 6.884, 'eval_samples_per_second': 41.11, 'eval_steps_per_second': 5.23, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████▏| 1600/1752 [19:18<01:46,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0125, 'learning_rate': 4.337899543378996e-06, 'epoch': 5.48}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                   \n",
            "100%|██████████| 1752/1752 [21:11<00:00,  1.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.05626462772488594, 'eval_runtime': 6.9718, 'eval_samples_per_second': 40.592, 'eval_steps_per_second': 5.164, 'epoch': 6.0}\n",
            "{'train_runtime': 1280.6242, 'train_samples_per_second': 10.935, 'train_steps_per_second': 1.368, 'train_loss': 0.060590083332366595, 'epoch': 6.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1752, training_loss=0.060590083332366595, metrics={'train_runtime': 1280.6242, 'train_samples_per_second': 10.935, 'train_steps_per_second': 1.368, 'train_loss': 0.060590083332366595, 'epoch': 6.0})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Jy4sOY2omlkB"
      },
      "outputs": [],
      "source": [
        "# name = 't5'\n",
        "\n",
        "saved_name = '_'.join([MODEL_NAME, str(N_EPOCHS)+'ep', str(BATCH_SIZE)+'b'])\n",
        "\n",
        "dir = MODEL_NAME+'/'+saved_name\n",
        "\n",
        "trainer.save_model(\"/home/anastasiia.demidova/srl/srl_transformers/models/\"+dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▅▁▂▅██</td></tr><tr><td>eval/runtime</td><td>█▆▄▅▁▅</td></tr><tr><td>eval/samples_per_second</td><td>▁▃▅▄█▄</td></tr><tr><td>eval/steps_per_second</td><td>▁▃▅▄█▄</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>train/learning_rate</td><td>█▇▆▅▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▂▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.05626</td></tr><tr><td>eval/runtime</td><td>6.9718</td></tr><tr><td>eval/samples_per_second</td><td>40.592</td></tr><tr><td>eval/steps_per_second</td><td>5.164</td></tr><tr><td>train/epoch</td><td>6.0</td></tr><tr><td>train/global_step</td><td>1752</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0125</td></tr><tr><td>train/total_flos</td><td>7592211947520000.0</td></tr><tr><td>train/train_loss</td><td>0.06059</td></tr><tr><td>train/train_runtime</td><td>1280.6242</td></tr><tr><td>train/train_samples_per_second</td><td>10.935</td></tr><tr><td>train/train_steps_per_second</td><td>1.368</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">t5-large_6ep_8b</strong> at: <a href='https://wandb.ai/profii/%3Cnlp-project%3E/runs/boa9oyfd' target=\"_blank\">https://wandb.ai/profii/%3Cnlp-project%3E/runs/boa9oyfd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231110_114035-boa9oyfd/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI_A9TRTW7Jx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5sgXH36TQeO"
      },
      "source": [
        "## Predicting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lh3TsBIkCzu2"
      },
      "outputs": [],
      "source": [
        "path_test = '/home/anastasiia.demidova/srl/srl_transformers/dataset/test_no_answers.tsv'\n",
        "path_dev = '/home/anastasiia.demidova/srl/srl_transformers/dataset/dev.tsv'\n",
        "\n",
        "df_test = pd.read_csv(path_test, sep='\\t', header= None, names=['data'], quoting=3)\n",
        "\n",
        "df_testo = pd.read_csv(path_test, sep='\\t', header= None, names=['data'],\n",
        "                      quoting=3, skip_blank_lines=False).fillna('_nan')\n",
        "\n",
        "df_dev = pd.read_csv(path_dev, sep='\\t', header= None, names=['data', 'labels'], quoting=3)\n",
        "\n",
        "df_devo = pd.read_csv(path_dev, sep='\\t', header= None, names=['data', 'labels'],\n",
        "                      quoting=3, skip_blank_lines=False).fillna('_nan')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2dKHoujon-J7"
      },
      "outputs": [],
      "source": [
        "df_devo.drop('labels', axis='columns', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW6wNhnwN7Yj",
        "outputId": "eb189fde-f533-414c-9bf3-b153f8b8452f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((9444, 1), (9804, 1))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.shape, df_testo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmfHSDB1h4q6",
        "outputId": "752ec699-c1a6-40ee-e1c3-5d509c6e3a74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8363, 2), (8646, 1))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_dev.shape, df_devo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dir = MODEL_NAME + '/'+ saved_name\n",
        "# MODEL_NAME, saved_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YvKfjnpAS4p3"
      },
      "outputs": [],
      "source": [
        "saved_model_name = 't5-large_6ep_8b'\n",
        "dir = 't5-large/'+saved_model_name\n",
        "\n",
        "# saved_model_name = 'flan-t5_10ep_8b'\n",
        "# dir = 'flan-t5/'+saved_model_name\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"/home/anastasiia.demidova/srl/srl_transformers/models/\"+dir).to('cuda')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/home/anastasiia.demidova/srl/srl_transformers/models/\"+dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Sk1iHQya4wE4"
      },
      "outputs": [],
      "source": [
        "# Separating data into sentences with empty lines (NaN)\n",
        "\n",
        "def separate_text_end(df):\n",
        "    # pattern = [\"###\", \"Instruction:\", \"Find\", \"all\", \"aspects\", \",\", \"objects\", \"and\", \"predicates\", \".\\n\\n###\", \"Input:\"]\n",
        "    # end_pattern = [\"\\n\\n###\", \"Response:\"]\n",
        "    PATTERN = [\"Sentence:\"]\n",
        "    END_PATTERN = [\"\\n\\naspect\", \",\", \"object\", \"and\", \"predicate\", \":\"]\n",
        "    input = []\n",
        "    sentence = []\n",
        "\n",
        "    for word in df['data']:\n",
        "        if word == '_nan':\n",
        "            input.append(PATTERN + sentence + END_PATTERN)\n",
        "            sentence = []\n",
        "        else:\n",
        "            word = re.sub(r\"[\\\"\\—\\#\\$\\%\\&\\'\\(\\)\\*\\+\\,\\–\\-\\/\\:\\;\\<\\=\\>\\?\\@\\[\\\\\\]\\^\\?\\!\\_\\`\\{\\|\\}\\~\\«\\»ѣ\\№]\", \",\", word)\n",
        "            word = re.sub(r\"[,]+\", \",\", word)\n",
        "            word = re.sub(r\"[.]+\", \".\", word)\n",
        "\n",
        "            sentence.append(word)\n",
        "\n",
        "    return input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "283"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(separate_text_end(df_devo))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iQxPIgDj6gF-"
      },
      "outputs": [],
      "source": [
        "# nlp = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L60XjfndFUW",
        "outputId": "003284ee-d3b0-4f33-e8ff-c906117fb71a"
      },
      "outputs": [],
      "source": [
        "# sents = separate_text_end(df_devo)\n",
        "\n",
        "# # print(sents[0])\n",
        "# res = nlp(' '.join(sents[0]))[0]\n",
        "\n",
        "# print(res['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8Yhml1rp1cE",
        "outputId": "00e6a57c-8da3-4f15-e9c0-9c62c66e786a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/anastasiia.demidova/miniconda3/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Sentence:', 'meanwhile', ',', 'though', 'windows', '8', 'is', 'significantly', 'at', 'greater', 'risk', ',', '1', '.', '73', 'percent', ',', 'compared', 'to', 'windows', '8', '.', '1', ',', 'according', 'to', 'redmond', ',', 's', 'report', ',', 'it', ',', 's', 'still', 'significantly', 'safer', 'than', 'windows', '7', ',', 'windows', 'xp', ',', 'or', 'windows', 'vista', '.', '\\n\\naspect', ',', 'object', 'and', 'predicate', ':']\n",
            "[ risk, safer | aspect ] [ windows 8, windows 8, windows 7, windows xp, windows vista | object ] [ greater, safer | predicate ]\n",
            "['Sentence:', 'windows', '7', 'is', 'still', 'going', 'strong', 'even', 'though', 'the', 'day', 'was', 'about', 'windows', '8', ',', 'microsoft', 'announced', 'it', ',', 's', 'approaching', '450', 'million', 'copies', 'of', 'windows', '7', 'sold', 'thus', 'far', ',', 'with', 'windows', '7', 'consumer', 'usage', 'coming', 'in', 'greater', 'than', 'windows', 'xp', '.', '\\n\\naspect', ',', 'object', 'and', 'predicate', ':']\n",
            "[ consumer usage | aspect ] [ windows, windows, windows | object ] [ greater | predicate ]\n",
            "['Sentence:', 'i', 'have', 'tried', 'windows', '8', 'and', 'it', ',', 's', 'lighter', 'than', 'windows', 'xp', '.', '\\n\\naspect', ',', 'object', 'and', 'predicate', ':']\n",
            "[ | aspect ] [ windows, windows xp | object ] [ lighter | predicate ]\n"
          ]
        }
      ],
      "source": [
        "sents = separate_text_end(df_devo)\n",
        "\n",
        "for s in sents[:3]:\n",
        "    input_ids = tokenizer.encode(s, return_tensors=\"pt\", is_split_into_words=True)\n",
        "\n",
        "    outputs = model.generate(input_ids.to(\"cuda\"), no_repeat_ngram_size=6,\n",
        "                             max_new_tokens=2048,\n",
        "                             num_return_sequences=1, early_stopping=True)\n",
        "\n",
        "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    print(s)\n",
        "    print(decoded)\n",
        "    # res = []\n",
        "    # for d in decoded.split():\n",
        "    #     if d.isdigit() and int(d) <= 6:\n",
        "    #         res.append(ids_to_labels[d])\n",
        "    #     else:\n",
        "    #         res.append('O')\n",
        "\n",
        "    # if len(res) != len(s):\n",
        "    #     print('Nooo')\n",
        "    #     for i in range(len(res), len(s)):\n",
        "    #             res.append('O')\n",
        "\n",
        "    # if len(res) != len(s):\n",
        "    #     print('Nooo')\n",
        "    # print(res)\n",
        "    # print('--------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HqULkzoYp1Yr"
      },
      "outputs": [],
      "source": [
        "# MAX_LENGTH = 180\n",
        "\n",
        "def evaluate(dfo):\n",
        "    # indexes_nan = []\n",
        "    labels_list = []\n",
        "    sents = separate_text_end(dfo)\n",
        "    i = 0\n",
        "\n",
        "    for sent in tqdm(sents):\n",
        "        input_ids = tokenizer.encode(sent, return_tensors=\"pt\", is_split_into_words=True)\n",
        "\n",
        "        outputs = model.generate(input_ids.to(\"cuda\"), no_repeat_ngram_size=6,\n",
        "                                max_new_tokens=2048,\n",
        "                                num_return_sequences=1, early_stopping=True)\n",
        "\n",
        "        decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        if i < 8:\n",
        "            i += 1\n",
        "            print(len(decoded))\n",
        "            # print(len(sent))\n",
        "            print(decoded)\n",
        "            print('--------')\n",
        "            # print(labels_list)\n",
        "\n",
        "        labels_list.append(decoded)\n",
        "\n",
        "    return labels_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ta3f_08cYwnC"
      },
      "outputs": [],
      "source": [
        "model_name = 'dev'\n",
        "# model_name = 'test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt7buh69F9dR",
        "outputId": "d41a8792-2595-4ba3-a21e-c072387be4e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/283 [00:01<05:35,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "127\n",
            "[ risk, safer | aspect ] [ windows 8, windows 8, windows 7, windows xp, windows vista | object ] [ greater, safer | predicate ]\n",
            "--------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 2/283 [00:01<04:04,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90\n",
            "[ consumer usage | aspect ] [ windows, windows, windows | object ] [ greater | predicate ]\n",
            "--------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 3/283 [00:02<03:32,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69\n",
            "[ | aspect ] [ windows, windows xp | object ] [ lighter | predicate ]\n",
            "--------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 4/283 [00:03<03:36,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101\n",
            "[ resources | aspect ] [ windows 8, windows 7, windows xp | object ] [ lighter, heavier | predicate ]\n",
            "--------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 5/283 [00:04<03:39,  1.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "83\n",
            "[ choosing | aspect ] [ windows, windows, xp, xp | object ] [ simpler | predicate ]\n",
            "--------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 6/283 [00:04<03:38,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101\n",
            "[ upgrading | aspect ] [ windows, windows, windows | object ] [ simpler, less expensive | predicate ]\n",
            "--------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 7/283 [00:05<03:34,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78\n",
            "[ | aspect ] [ windows, windows xp, windows 7 | object ] [ safer | predicate ]\n",
            "--------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 8/283 [00:06<03:28,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "96\n",
            "[ virus infection | aspect ] [ windows, windows, windows | object ] [ safer, safer | predicate ]\n",
            "--------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [03:45<00:00,  1.25it/s]\n"
          ]
        }
      ],
      "source": [
        "if model_name == 'dev':\n",
        "    labels_list = evaluate(df_devo)\n",
        "else:\n",
        "    labels_list = evaluate(df_testo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "asaX0l9wRDsg",
        "outputId": "84c04f99-746a-4f2a-a1e1-b3e0b7af1ce2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[ consumer usage | aspect ] [ windows, windows, windows | object ] [ greater | predicate ]'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_list[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Yjm79DLZUdLV"
      },
      "outputs": [],
      "source": [
        "from more_itertools import locate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW_8nzWKPQdn",
        "outputId": "a74f993f-eada-48e7-af45-6c2d6163e9c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8646/8646 [00:00<00:00, 982709.67it/s]\n"
          ]
        }
      ],
      "source": [
        "labels = []\n",
        "i = 0\n",
        "sent = []\n",
        "labeled_sent = [] # for output\n",
        "tags = []\n",
        "BIO = ['Aspect', 'Object', 'Predicate']\n",
        "indexes_nan = [0]\n",
        "\n",
        "if model_name == 'dev':\n",
        "    df = df_devo\n",
        "else:\n",
        "    df = df_testo\n",
        "\n",
        "for d in tqdm(df.data):\n",
        "    if d == '_nan':\n",
        "        labels = labels_list[i].split('] [')\n",
        "\n",
        "        # print(sent)\n",
        "        # print(tags)\n",
        "        # print(labels)\n",
        "\n",
        "        for l in range(len(labels)):\n",
        "            word_list = labels[l].split('|')[0].replace('[', '').strip().split(',')\n",
        "\n",
        "            # print(l)\n",
        "            # print(word_list)\n",
        "\n",
        "            for j in word_list:\n",
        "                j = j.strip()\n",
        "                # print(j)\n",
        "                if ' ' in j:\n",
        "                    for beg, elem in enumerate(j.split()):\n",
        "                        if beg == 0:\n",
        "                            if elem in sent: tags[sent.index(elem)] = 'B-' + BIO[l]\n",
        "                        else:\n",
        "                            if elem in sent: tags[sent.index(elem)] = 'I-' + BIO[l]\n",
        "                elif j in sent:\n",
        "                    indices = locate(sent, lambda x: x == j)\n",
        "                    for inde in indices:\n",
        "                        tags[inde] = 'B-' + BIO[l]\n",
        "\n",
        "        # print(tags)\n",
        "        i += 1\n",
        "        labeled_sent.extend(tags)\n",
        "        indexes_nan.append(indexes_nan[-1] + len(tags))\n",
        "        sent = []\n",
        "        tags = []\n",
        "    else:\n",
        "        sent.append(d)\n",
        "        tags.append('O')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EP3Z7jqj8K0",
        "outputId": "eea13a4f-9d3e-46f8-9215-4130a1bfed03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 47, 90, 104, 127, 170, 206, 223, 249, 284]\n"
          ]
        }
      ],
      "source": [
        "print(indexes_nan[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-4WLsAPVlPV",
        "outputId": "92b1b92d-df60-446c-e87a-a7021389e703"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8363"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(labeled_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bXQxmURCPQcC"
      },
      "outputs": [],
      "source": [
        "if model_name == 'dev':\n",
        "    df_dev['labels'] = labeled_sent # dev\n",
        "else:\n",
        "    df_test['labels'] = labeled_sent # test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fGm9Z8lnZqRV",
        "outputId": "c90629cc-5de5-400a-bff4-b06436554094"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             data       labels\n",
            "0       meanwhile            O\n",
            "1               ,            O\n",
            "2          though            O\n",
            "3         windows     B-Object\n",
            "4               8     I-Object\n",
            "5              is            O\n",
            "6   significantly            O\n",
            "7              at            O\n",
            "8         greater  B-Predicate\n",
            "9            risk     B-Aspect\n",
            "10              (            O\n",
            "11              1            O\n",
            "12              .            O\n",
            "13             73            O\n",
            "14        percent            O\n",
            "15              )            O\n",
            "16       compared            O\n",
            "17             to            O\n",
            "18        windows            O\n",
            "19              8            O\n",
            "20              .            O\n",
            "21              1            O\n",
            "22              ,            O\n",
            "23      according            O\n",
            "24             to            O\n",
            "25        redmond            O\n",
            "26              '            O\n",
            "27              s            O\n",
            "28         report            O\n",
            "29              ,            O\n",
            "30             it            O\n",
            "31              '            O\n",
            "32              s            O\n",
            "33          still            O\n",
            "34  significantly            O\n",
            "35          safer  B-Predicate\n",
            "36           than            O\n",
            "37        windows            O\n",
            "38              7     I-Object\n",
            "39              ,            O\n",
            "40        windows            O\n",
            "41             xp     I-Object\n",
            "42              ,            O\n",
            "43             or            O\n",
            "44        windows            O\n",
            "45          vista     I-Object\n",
            "46              .            O\n",
            "47        windows     B-Object\n",
            "48              7            O\n",
            "49             is            O\n"
          ]
        }
      ],
      "source": [
        "if model_name == 'dev':\n",
        "    print(df_dev.head(50))\n",
        "else:\n",
        "    print(df_test.head(50))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq1DeVvrsIJT"
      },
      "source": [
        "## Saving Result Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU77rJ-CHNZ4",
        "outputId": "220504b7-ba3c-439f-c91d-784d87e437aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('t5-large/t5-large_6ep_8b_aspect:', 'dev')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir, model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lIfq98kdmwAG"
      },
      "outputs": [],
      "source": [
        "if model_name == 'dev':\n",
        "    df_dev.to_csv('/home/anastasiia.demidova/srl/srl_transformers/results/'+dir+'_'+model_name+'.tsv',\n",
        "            header=None, index=False, quoting=3, sep='\\t', encoding='utf-8')\n",
        "else:\n",
        "    df_test.to_csv('/home/anastasiia.demidova/srl/srl_transformers/results/'+dir+'_'+model_name+'.tsv',\n",
        "            header=None, index=False, quoting=3, sep='\\t', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4gL2jMzPbNq",
        "outputId": "982b3018-137e-449c-bdbf-4062a72e2d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A miracle happened ^-^/***\n"
          ]
        }
      ],
      "source": [
        "with open('/home/anastasiia.demidova/srl/srl_transformers/results/'+dir+'_'+model_name+'.tsv') as input:\n",
        "    lines = [line for line in input if line.strip()]\n",
        "\n",
        "with open('/home/anastasiia.demidova/srl/srl_transformers/results/'+dir+'_'+model_name+'_post.tsv', 'w') as output:\n",
        "    i = 0\n",
        "    for line in lines:\n",
        "        # if '_nan' in line:\n",
        "        #     output.write(\"\\n\")\n",
        "        # else:\n",
        "\n",
        "        output.write(line)\n",
        "        if i+1 in (indexes_nan):\n",
        "            # print(line)\n",
        "            output.write(\"\\n\")\n",
        "        i += 1\n",
        "\n",
        "\n",
        "print('A miracle happened ^-^/***')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "2VUka9ENtj0N"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
